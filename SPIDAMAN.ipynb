{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "165eccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENV 0 made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\devtools\\Anaconda\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "from spidermanENV import Spiderman_ENV\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.vec_env.vec_monitor import VecMonitor\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "import os\n",
    "os.system(\"taskkill /f /im  ruffle.exe\")\n",
    "\n",
    "\n",
    "env = [lambda i=i: Spiderman_ENV(i) for i in range(1)]\n",
    "env = DummyVecEnv(env)\n",
    "env = VecFrameStack(env,3)\n",
    "env = VecMonitor(env)\n",
    "\n",
    "# env = Spiderman_ENV(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3346bc9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9eb1bc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Check Environment    \n",
    "from stable_baselines3.common import env_checker\n",
    "\n",
    "# env_checker.check_env(env)\n",
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True\n",
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'\n",
    "\n",
    "\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eccc13b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J:\\devtools\\Anaconda\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from 'J:\\\\devtools\\\\Anaconda\\\\lib\\\\site-packages\\\\cloudpickle\\\\cloudpickle.py'>\n",
      "  warnings.warn(\n",
      "J:\\devtools\\Anaconda\\lib\\site-packages\\stable_baselines3\\common\\save_util.py:166: UserWarning: Could not deserialize object clip_range. Consider using `custom_objects` argument to replace this object.\n",
      "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from 'J:\\\\devtools\\\\Anaconda\\\\lib\\\\site-packages\\\\cloudpickle\\\\cloudpickle.py'>\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Box' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, tensorboard_log=LOG_DIR, verbose=1, buffer_size=10000000, learning_starts=10000)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# model = TD3(\"MlpPolicy\", env, action_noise=action_noise, tensorboard_log=LOG_DIR, verbose=1, buffer_size=10000000, learning_starts=10000)\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# n steps is how many steps PER ENVIRONMENT\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# model = PPO(\"MlpPolicy\",env, n_steps = 512, batch_size = 128,tensorboard_log=LOG_DIR, verbose=1)\u001b[39;00m\n\u001b[0;32m     25\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,env, n_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m,  batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m,policy_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(net_arch\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m512\u001b[39m,\u001b[38;5;241m512\u001b[39m]),tensorboard_log\u001b[38;5;241m=\u001b[39mLOG_DIR, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPPO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m512-512-512-vectorppo/best_model_240000\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mJ:\\devtools\\Anaconda\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:684\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    682\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_env(env, data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    683\u001b[0m \u001b[38;5;66;03m# Check if given env is valid\u001b[39;00m\n\u001b[1;32m--> 684\u001b[0m \u001b[43mcheck_for_correct_spaces\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobservation_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_space\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;66;03m# Discard `_last_obs`, this will force the env to reset before training\u001b[39;00m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;66;03m# See issue https://github.com/DLR-RM/stable-baselines3/issues/597\u001b[39;00m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_reset \u001b[38;5;129;01mand\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mJ:\\devtools\\Anaconda\\lib\\site-packages\\stable_baselines3\\common\\utils.py:227\u001b[0m, in \u001b[0;36mcheck_for_correct_spaces\u001b[1;34m(env, observation_space, action_space)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_for_correct_spaces\u001b[39m(env: GymEnv, observation_space: spaces\u001b[38;5;241m.\u001b[39mSpace, action_space: spaces\u001b[38;5;241m.\u001b[39mSpace) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m    Checks that the environment has same spaces as provided ones. Used by BaseAlgorithm to check if\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    spaces match after loading the model with given env.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    :param action_space: Action space to check against\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mobservation_space\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_space\u001b[49m:\n\u001b[0;32m    228\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mObservation spaces do not match: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m action_space \u001b[38;5;241m!=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space:\n",
      "File \u001b[1;32mJ:\\devtools\\Anaconda\\lib\\site-packages\\gym\\spaces\\box.py:140\u001b[0m, in \u001b[0;36mBox.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Box) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m \u001b[38;5;241m==\u001b[39m other\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow, other\u001b[38;5;241m.\u001b[39mlow) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mallclose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhigh, other\u001b[38;5;241m.\u001b[39mhigh)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Box' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3 import TD3\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "\n",
    "\n",
    "\n",
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "# model = DDPG(\"MlpPolicy\", env, action_noise=action_noise, tensorboard_log=LOG_DIR, verbose=1, buffer_size=10000000, learning_starts=10000)\n",
    "# model = TD3(\"MlpPolicy\", env, action_noise=action_noise, tensorboard_log=LOG_DIR, verbose=1, buffer_size=10000000, learning_starts=10000)\n",
    "\n",
    "\n",
    "# n steps is how many steps PER ENVIRONMENT\n",
    "# model = PPO(\"MlpPolicy\",env, n_steps = 512, batch_size = 128,tensorboard_log=LOG_DIR, verbose=1)\n",
    "model = PPO(\"MlpPolicy\",env, n_steps = 1024,  batch_size = 256, learning_rate=1e-5,policy_kwargs=dict(net_arch=[512,512,512]),tensorboard_log=LOG_DIR, verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = PPO.load('512-512-512-vectorppo/best_model_240000',env) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c53e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.learn(total_timesteps=9999999999999999999999999999, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa236f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model = PPO(\"MlpPolicy\",env, tensorboard_log=LOG_DIR, verbose=1)\n",
    "# # model.set_parameters('train/best_model_180000')\n",
    "# model =PPO.load('train/best_model_180000') \n",
    "# model.set_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "# env = Spiderman_ENV(0)\n",
    "# os.system(\"taskkill /f /im  ruffle.exe\")\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(model, env, n_eval_episodes=30, deterministic=True)\n",
    "\n",
    "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40487a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
